# Waypoint VLM training config — LIBERO
# Usage: torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_waypoint.py --mode vlm --config configs/waypoint_vlm_libero.yaml

robot_type: libero

# Data paths
wp_rlds_dir: /workspace/data/libero/libero_object_wp_001/waypoint_filtered_rlds__libero/1.0.0
dataset_statistics_path: /workspace/data/libero_object_no_noops/1.0.0

# Model architecture
paligemma_variant: gemma_2b
action_expert_variant: gemma_300m  # Only needed for weight extraction
precision: bfloat16

# Waypoint config
num_waypoints: 7
max_token_len: 256
stride: 1

# Pretrained weights (Pi0.5 base — will extract PaliGemma portion)
pretrained_weight_path: /workspace/models/pi05_base_pytorch

# Training hyperparameters
batch_size: 320
num_train_steps: 2000
warmup_steps: 40
peak_lr: 3.0e-5
end_lr: 1.0e-7

# Normalization
norm_type: q99

# Image augmentation (matching galaxea_0 reference defaults)
image_aug: true
image_aug_cfg:
  random_resized_crop_scale: [0.9, 1.0]
  brightness: 0.2
  contrast: [0.8, 1.2]
  saturation: [0.8, 1.2]
  hue: 0.05

# Shuffle
shuffle_buffer_size: 5000

# Logging and checkpointing
exp_name: waypoint_vlm_libero_fix1
checkpoint_dir: checkpoints/waypoint_vlm_libero_fix1
save_interval: 200
log_interval: 5
wandb_enabled: true

# LoRA (set to true for low-memory training)
lora_enabled: false
lora_rank: 16
lora_alpha: 16.0
train_vision_encoder: true

# Resume from checkpoint
resume: false
