# Waypoint VLA evaluation config â€” LIBERO Object
# Usage: python -m openpi.waypoint.eval_libero --config configs/eval_waypoint_libero.yaml

robot_type: libero
task_suite: libero_spatial

# Model checkpoints (set these to your trained checkpoint directories)
vlm_checkpoint: /workspace/models/vlm
ae_checkpoint: /workspace/models/ae

# Data / normalization
dataset_statistics_path: /workspace/data/dataset_statistics.json

# Model dimensions
model_action_dim: 32
model_proprio_dim: 32
horizon_steps: 32
num_waypoints: 7
max_token_len: 256

# Model architecture
paligemma_variant: gemma_2b
action_expert_variant: gemma_300m
precision: bfloat16

# Normalization
norm_type: q99

# Inference optimization
vlm_precision: bfloat16
torch_compile: true

# Evaluation
num_trials_per_task: 10
num_steps_wait: 10

# Video output
video_out_path: data/libero/videos_wp_spatial
